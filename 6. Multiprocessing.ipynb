{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about this for now...\n",
    "mp.set_start_method('fork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "The second most common way to write concurrent programs is with the use of multiprocessing (I'm leaving asyncio aside). It's the oldest concurrency concept, as processes predate threads.\n",
    "\n",
    "In a multiprocessing program, we'll create multiple processes that will be ran concurrently (and potentially in parallel) **by the operating system**. It's important to stress the fact that when we write multiprocessing code, we're giving full authority to the OS to manage and schedule our processes.\n",
    "\n",
    "#### How can multiprocessing help with the GIL?\n",
    "\n",
    "The main issue with the GIL was to protect **shared data** (low level data like reference counts) between threads. But, what if there's NO shared data at all? If you remember from our OS review before, data is shared only **within the same process**. Different processes DON'T share data. Which means that there's no GIL to worry about.\n",
    "\n",
    "#### Then, why not to use multiprocessing all the time?\n",
    "\n",
    "If multiprocessing doesn't suffer from the GIL, why not to use it instead of multithreading? As usual with computers, there's no free lunch. Multiprocessing suffers from 2 major drawbacks:\n",
    "\n",
    "##### 1. Slower, resource heavy\n",
    "\n",
    "Creating new processes is a lot slower than spawning threads. And by spawning new processes, we're duplicating all the information of our processes: share data, file descriptors, etc.\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/multiple_process.png\" />\n",
    "</center>\n",
    "\n",
    "\n",
    "##### 2. Hard to orchestrate\n",
    "\n",
    "As processes don't share data, it's hard to coordinate results and flags between multiple processes. We'll see this in an example later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Process` API\n",
    "\n",
    "The `multiprocessing` module has a `Process` class with an API very similar to the one in `threading.Thread`.\n",
    "\n",
    "> **Warning**: Always make sure you're using the module `multiprocessing` and not `subprocess`.\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say_hello():\n",
    "    myself = mp.current_process()\n",
    "    print(f'Hello World from \"{myself.name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Process(target=say_hello, name=\"My First Process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from \"My First Process\"\n"
     ]
    }
   ],
   "source": [
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to free up resources allocated by such process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find prime example\n",
    "\n",
    "Let's verify if processes can actually run in parallel by running again our \"check primes\" example. If that's the case, we'll see a significant improvement in time. Remember, our multi-threaded version took ~4 seconds to process all 10 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    if n in (2, 3):\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "    for divisor in range(3, n, 2):\n",
    "        if n % divisor == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prime_mixture.txt') as fp:\n",
    "    numbers = [int(n.strip()) for n in fp.read().split() if n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15492781, 15492787, 15492803, 15492811, 15492810]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime_worker(number):\n",
    "    if is_prime(number):\n",
    "        print(f'{number} IS PRIME ✅', flush=True)\n",
    "    else:\n",
    "        print(f'{number} IS NOT PRIME ❌', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [Process(target=check_prime_worker, args=(number,)) for number in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15492810 IS NOT PRIME ❌\n",
      "15492811 IS PRIME ✅\n",
      "15492803 IS PRIME ✅\n",
      "15492859 IS PRIME ✅\n",
      "15527509 IS PRIME ✅\n",
      "15492781 IS PRIME ✅\n",
      "15492833 IS PRIME ✅\n",
      "15492787 IS PRIME ✅\n",
      "15502547 IS PRIME ✅\n",
      "15520301 IS PRIME ✅\n"
     ]
    }
   ],
   "source": [
    "[p.start() for p in processes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.join() for p in processes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7560350894927979"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.close() for p in processes];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a clear running time improvement, from ~4 seconds to ~0.7, which means that processes are indeed running in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing data with processes\n",
    "\n",
    "It's not as simple as with threads to share data. In our multithreaded example, we just passed a `results` dictionary that was used by the threads to store their results. In our case, we can't do that and we just had to print the result, which is useless for a real life program.\n",
    "\n",
    "There are several mechanisms to share data with multiprocessing, in this lesson we'll focus in `Queue`s and `Pipe`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queues\n",
    "\n",
    "Queues in the multiprocessing module have a very similar API than the thread safe ones in the `queue` module, so let's just see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_to_do = mp.JoinableQueue()\n",
    "work_done = mp.SimpleQueue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "[work_to_do.put(n) for n in numbers];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_consumer(task_queue, results_queue):\n",
    "    while True:\n",
    "        try:\n",
    "            number = task_queue.get_nowait()\n",
    "            result = is_prime(number)\n",
    "            results_queue.put((number, result))\n",
    "        except queue.Empty:\n",
    "            print('No more numbers to process. Exiting...')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pool = [Process(target=process_consumer, args=(work_to_do, work_done)) for _ in range(MAX_WORKERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more numbers to process. Exiting...\n",
      "No more numbers to process. Exiting...\n",
      "No more numbers to process. Exiting...\n",
      "No more numbers to process. Exiting...\n",
      "No more numbers to process. Exiting...\n"
     ]
    }
   ],
   "source": [
    "[p.start() for p in process_pool];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.join() for p in process_pool];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.close() for p in process_pool];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15492810 IS NOT PRIME ❌\n",
      "15492781 IS PRIME ✅\n",
      "15492787 IS PRIME ✅\n",
      "15492803 IS PRIME ✅\n",
      "15492833 IS PRIME ✅\n",
      "15492811 IS PRIME ✅\n",
      "15492859 IS PRIME ✅\n",
      "15502547 IS PRIME ✅\n",
      "15520301 IS PRIME ✅\n",
      "15527509 IS PRIME ✅\n"
     ]
    }
   ],
   "source": [
    "while not work_done.empty():\n",
    "    number, prime = work_done.get()\n",
    "    if prime:\n",
    "        print(f'{number} IS PRIME ✅')\n",
    "    else:\n",
    "        print(f'{number} IS NOT PRIME ❌')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipes\n",
    "\n",
    "Pipes are not as safe as Queues, as data can be corrupted and it's hard to know when to start polling the queue. In our following example, we're assuming we're going to receive all 10 messages that we're expecting to receive given we're starting 10 processes. But the reality is that one of those processes could die before sending the message and we're going to wait forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_conn, worker_conn = mp.Pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prime_worker(number, pipe_connection):\n",
    "    result = is_prime(number)\n",
    "    pipe_connection.send((number, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [Process(target=process_prime_worker, args=(number, worker_conn)) for number in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.start() for p in processes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.join() for p in processes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.close() for p in processes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15492810 IS NOT PRIME ❌\n",
      "15492803 IS PRIME ✅\n",
      "15492787 IS PRIME ✅\n",
      "15502547 IS PRIME ✅\n",
      "15492859 IS PRIME ✅\n",
      "15492811 IS PRIME ✅\n",
      "15527509 IS PRIME ✅\n",
      "15492781 IS PRIME ✅\n",
      "15492833 IS PRIME ✅\n",
      "15520301 IS PRIME ✅\n"
     ]
    }
   ],
   "source": [
    "received = 0\n",
    "while received < 10:\n",
    "    number, prime_result = main_conn.recv()\n",
    "    received += 1\n",
    "    if prime_result:\n",
    "        print(f'{number} IS PRIME ✅')\n",
    "    else:\n",
    "        print(f'{number} IS NOT PRIME ❌')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pools\n",
    "\n",
    "The `multiprocessing` module contains a very useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 15492803 is prime\n",
      "Number 15492810 is NOT prime\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=4) as pool:\n",
    "    n = random.choice(numbers)\n",
    "    result = pool.apply_async(is_prime, (n, ))\n",
    "    print(f\"Number {n} {'is prime' if result.get() else 'is NOT prime'}\")\n",
    "    \n",
    "    n = random.choice(numbers)\n",
    "    result = pool.apply_async(is_prime, (n, ))\n",
    "    print(f\"Number {n} {'is prime' if result.get() else 'is NOT prime'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we're using our regular `is_prime` function. This is important, as there seems to be some \"data sharing\" behind the scenes, which simplifies the API. The `apply_async` function submits a \"task\" to perform, it's computed behind the scenes and an `AsyncResult` is returned.\n",
    "\n",
    "Pools have other useful methods, like for example `map` and `map_async` (and other variants like `imap` or `starmap`). The `map` method is similar to the `map` builtin function, or a list comprehension. Let's see an example to process all our prime numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 primes for a total of 10\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=10) as pool:\n",
    "    results = pool.map(is_prime, numbers)\n",
    "    print(f\"Found {sum(results)} primes for a total of {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575781345367432"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `map` interface is very convenient, it feels like a regular synchronous Python API, but behind the scenes is using a pool of multiple processes. In our next lesson, when we talk about `concurrent.futures` we'll see why familiar and intuitive interfaces make our life easier.\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lesson we're just scratching the surface of multiprocessing work. Sadly, working with multiple processes is a lot harder than using threads, as it requires a deeper understanding of the operating system and it's a lot less safe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
